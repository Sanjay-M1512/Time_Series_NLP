{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6501f577",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Price           Close       High        Low       Open     Volume\n",
      "Ticker           AAPL       AAPL       AAPL       AAPL       AAPL\n",
      "Date                                                             \n",
      "2020-01-02  72.468277  72.528597  71.223274  71.476615  135480400\n",
      "2020-01-03  71.763725  72.523754  71.539337  71.696167  146322800\n",
      "2020-01-06  72.335556  72.374162  70.634539  70.885472  118387200\n",
      "2020-01-07  71.995369  72.600975  71.775804  72.345220  108872000\n",
      "2020-01-08  73.153481  73.455080  71.698566  71.698566  132079200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import random\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def main():\n",
    "    # ============================\n",
    "    # Step 0: Get input CSV filename\n",
    "    # ============================\n",
    "    filename = input(\"\").strip()\n",
    "    file_path = os.path.join(sys.path[0], filename)\n",
    "\n",
    "    # ============================\n",
    "    # Step 1: Read CSV file\n",
    "    # ============================\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"First 5 rows from the file:\")\n",
    "    print(df.head())\n",
    "    print()\n",
    "\n",
    "    # ============================\n",
    "    # Step 2: Prepare train/test split\n",
    "    # ============================\n",
    "    train_df = df.copy()\n",
    "    test_df = df.copy()\n",
    "\n",
    "    # ============================\n",
    "    # Step 3: Clean 'clean_text' column\n",
    "    # ============================\n",
    "    train_df['clean_text'] = train_df['clean_text'].fillna('')\n",
    "    test_df['clean_text'] = test_df['clean_text'].fillna('')\n",
    "\n",
    "    # Remove rows with empty text\n",
    "    train_df = train_df[train_df['clean_text'].str.strip() != '']\n",
    "    test_df = test_df[test_df['clean_text'].str.strip() != '']\n",
    "\n",
    "    # Lowercase all text\n",
    "    train_df['clean_text'] = train_df['clean_text'].str.lower()\n",
    "    test_df['clean_text'] = test_df['clean_text'].str.lower()\n",
    "\n",
    "    # ============================\n",
    "    # Step 4: Encode labels and create y_true AFTER cleaning\n",
    "    # ============================\n",
    "    label_mapping = {label: idx for idx, label in enumerate(df['sentiment'].unique())}\n",
    "    train_df['sentiment_encoded'] = train_df['sentiment'].map(label_mapping)\n",
    "    test_df['sentiment_encoded'] = test_df['sentiment'].map(label_mapping)\n",
    "    y_true = test_df['sentiment_encoded']  # must be AFTER cleaning\n",
    "\n",
    "    # ============================\n",
    "    # Step 5: Create a mock fastText predictor\n",
    "    # ============================\n",
    "    random.seed(42)\n",
    "    def fasttext_predict_mock(text):\n",
    "        return random.choice(df['sentiment'].unique())\n",
    "    test_df['pred_ft'] = test_df['clean_text'].apply(fasttext_predict_mock)\n",
    "\n",
    "    # ============================\n",
    "    # Step 6: Predict multi-class data with sklearn\n",
    "    # ============================\n",
    "    multi_pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=2000)),\n",
    "        (\"clf\", MultinomialNB())\n",
    "    ])\n",
    "    multi_pipeline.fit(train_df[\"clean_text\"], train_df[\"sentiment_encoded\"])\n",
    "    test_df['pred_sklearn'] = multi_pipeline.predict(test_df[\"clean_text\"])\n",
    "\n",
    "    # ============================\n",
    "    # Step 7: Create a mock GenAI predictor\n",
    "    # ============================\n",
    "    labels = df['sentiment'].unique().tolist()\n",
    "    random.seed(42)\n",
    "    def genai_predict_mock(text):\n",
    "        return random.choice(labels)\n",
    "    test_df['pred_genai'] = test_df['clean_text'].apply(genai_predict_mock)\n",
    "\n",
    "    # ============================\n",
    "    # Step 8: Evaluate all three models\n",
    "    # ============================\n",
    "    ft_acc   = accuracy_score(y_true, test_df['pred_ft'].map(label_mapping))\n",
    "    sk_acc   = accuracy_score(y_true, test_df['pred_sklearn'])\n",
    "    gen_acc  = accuracy_score(y_true, test_df['pred_genai'].map(label_mapping))\n",
    "\n",
    "    print(\"fastText Accuracy: \", round(ft_acc, 4))\n",
    "    print(\"sklearn Accuracy: \", round(sk_acc, 4))\n",
    "    print(\"GenAI Accuracy:   \", round(gen_acc, 4))\n",
    "    print()\n",
    "\n",
    "    # ============================\n",
    "    # Step 9: Build alignment comparison table\n",
    "    # ============================\n",
    "    test_df['agree_ft_sk']   = (test_df['pred_ft'] == test_df['pred_sklearn'].map({v:k for k,v in label_mapping.items()}))\n",
    "    test_df['agree_ft_gen']  = (test_df['pred_ft'] == test_df['pred_genai'])\n",
    "    test_df['agree_sk_gen']  = (test_df['pred_sklearn'].map({v:k for k,v in label_mapping.items()}) == test_df['pred_genai'])\n",
    "\n",
    "    alignment_results = test_df[['agree_ft_sk', 'agree_ft_gen', 'agree_sk_gen']].mean()\n",
    "    print(\"Alignment Results:\")\n",
    "    print(alignment_results)\n",
    "    print()\n",
    "\n",
    "    # ============================\n",
    "    # Step 10: Inspect mock fastText predictions\n",
    "    # ============================\n",
    "    test_df['ft_pred_raw'] = test_df['clean_text'].apply(lambda x: (fasttext_predict_mock(x), random.random()))\n",
    "    print(\"Sample fastText raw predictions:\")\n",
    "    print(test_df[['clean_text', 'ft_pred_raw']].head(5))\n",
    "    print()\n",
    "\n",
    "    # ============================\n",
    "    # Step 11: Interpretation\n",
    "    # ============================\n",
    "    print(\" Where fastText > sklearn?\")\n",
    "    print(test_df[(test_df['agree_ft_gen']) & (~test_df['agree_ft_sk'])].head(3))\n",
    "    print()\n",
    "\n",
    "    print(\" Where sklearn > fastText?\")\n",
    "    print(test_df[(~test_df['agree_ft_sk']) & (test_df['agree_sk_gen'])].head(3))\n",
    "    print()\n",
    "\n",
    "    print(\" Where GenAI > both?\")\n",
    "    print(test_df[\n",
    "        (test_df['pred_genai'].map(label_mapping) == y_true) &\n",
    "        (test_df['pred_sklearn'] != y_true) &\n",
    "        (test_df['pred_ft'].map(label_mapping) != y_true)\n",
    "    ].head(3))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
