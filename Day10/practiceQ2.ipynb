{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7ca0b74",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f206afa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    classification_report,\n",
    "    confusion_matrix\n",
    ")\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from nlp_utils import clean_text, split_labels, split_data\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Main Function\n",
    "# -----------------------------\n",
    "def main():\n",
    "\n",
    "    # -----------------------------\n",
    "    # STEP 1: Read dataset\n",
    "    # -----------------------------\n",
    "    filename = sys.argv[1] if len(sys.argv) > 1 else \"Sample.csv\"\n",
    "    file_path = os.path.join(sys.path[0], filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        print(\"Dataset not found.\")\n",
    "        return\n",
    "\n",
    "    df = pd.read_csv(file_path) if filename.endswith(\".csv\") else pd.read_excel(file_path)\n",
    "\n",
    "    # -----------------------------\n",
    "    # STEP 2: Train/Test Split\n",
    "    # -----------------------------\n",
    "    train, test = split_data(df)\n",
    "\n",
    "    # -----------------------------\n",
    "    # STEP 3: Text Cleaning\n",
    "    # -----------------------------\n",
    "    train[\"clean_text\"] = train[\"review\"].apply(clean_text)\n",
    "    test[\"clean_text\"] = test[\"review\"].apply(clean_text)\n",
    "\n",
    "    # -----------------------------\n",
    "    # STEP 4: TF-IDF\n",
    "    # -----------------------------\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_train = tfidf.fit_transform(train[\"clean_text\"])\n",
    "    X_test = tfidf.transform(test[\"clean_text\"])\n",
    "\n",
    "    # =================================================\n",
    "    # BINARY CLASSIFICATION\n",
    "    # =================================================\n",
    "    if \"binary_sentiment\" in train.columns:\n",
    "\n",
    "        y_train = train[\"binary_sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "        y_test = test[\"binary_sentiment\"].map({\"negative\": 0, \"positive\": 1})\n",
    "\n",
    "        model = LogisticRegression(max_iter=1000)\n",
    "        model.fit(X_train, y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        print(\"\\n===== BINARY MODEL =====\")\n",
    "        print(\"Accuracy:\", accuracy_score(y_test, preds))\n",
    "        print(classification_report(y_test, preds, zero_division=0))\n",
    "\n",
    "    # =================================================\n",
    "    # MULTI-CLASS CLASSIFICATION\n",
    "    # =================================================\n",
    "    if \"sentiment_encoded\" in train.columns:\n",
    "\n",
    "        model = MultinomialNB()\n",
    "        model.fit(X_train, train[\"sentiment_encoded\"])\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        print(\"\\n===== MULTI-CLASS MODEL =====\")\n",
    "        print(\"Accuracy:\", accuracy_score(test[\"sentiment_encoded\"], preds))\n",
    "        print(confusion_matrix(test[\"sentiment_encoded\"], preds))\n",
    "        print(classification_report(test[\"sentiment_encoded\"], preds, zero_division=0))\n",
    "\n",
    "    # =================================================\n",
    "    # MULTI-LABEL CLASSIFICATION\n",
    "    # =================================================\n",
    "    if \"emotion_labels\" in train.columns:\n",
    "\n",
    "        train[\"emotion_list\"] = train[\"emotion_labels\"].apply(split_labels)\n",
    "        test[\"emotion_list\"] = test[\"emotion_labels\"].apply(split_labels)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        Y_train = mlb.fit_transform(train[\"emotion_list\"])\n",
    "        Y_test = mlb.transform(test[\"emotion_list\"])\n",
    "\n",
    "        model = OneVsRestClassifier(LogisticRegression(max_iter=1000))\n",
    "        model.fit(X_train, Y_train)\n",
    "        preds = model.predict(X_test)\n",
    "\n",
    "        print(\"\\n===== MULTI-LABEL MODEL =====\")\n",
    "        print(\"Micro F1:\", f1_score(Y_test, preds, average=\"micro\", zero_division=0))\n",
    "        print(\"Macro F1:\", f1_score(Y_test, preds, average=\"macro\", zero_division=0))\n",
    "        print(classification_report(Y_test, preds, target_names=mlb.classes_, zero_division=0))\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f37bc712",
   "metadata": {},
   "source": [
    "### ***nlp_utils.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a199a558",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# -----------------------------\n",
    "# Built-in English stopwords\n",
    "# -----------------------------\n",
    "ENGLISH_STOPWORDS = set(\"\"\"\n",
    "a about above after again against all am an and any are as at be because been before\n",
    "being below between both but by do does doing down during each few for from further had\n",
    "has have having he her here hers him himself his how i if in into is it its itself me\n",
    "more most my myself no nor not of off on once only or other our ours ourselves out over\n",
    "own same she should so some such than that the their theirs them themselves then there\n",
    "these they this those through to too under until up very was we were what when where\n",
    "which while who whom why with you your yours yourself yourselves\n",
    "\"\"\".split())\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Text cleaning function\n",
    "# -----------------------------\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|@\\w+|[^a-z\\s]\", \"\", text)\n",
    "    words = [w for w in text.split() if w not in ENGLISH_STOPWORDS]\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Multi-label splitter\n",
    "# -----------------------------\n",
    "def split_labels(label_string):\n",
    "    if pd.isna(label_string) or label_string == \"\":\n",
    "        return []\n",
    "    return [l.strip() for l in label_string.split(\",\")]\n",
    "\n",
    "\n",
    "# -----------------------------\n",
    "# Train / Test split\n",
    "# -----------------------------\n",
    "def split_data(df, test_ratio=0.2, random_state=42):\n",
    "    train = df.sample(frac=1 - test_ratio, random_state=random_state)\n",
    "    test = df.drop(train.index)\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
