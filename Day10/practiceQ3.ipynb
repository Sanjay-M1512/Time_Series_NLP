{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd963936",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "374a3a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import random\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from nlp_utils import clean_text, split_data\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "\n",
    "def fasttext_predict_mock(text, labels):\n",
    "    return random.choice(labels)\n",
    "\n",
    "\n",
    "def genai_predict_mock(text, labels):\n",
    "    return random.choice(labels)\n",
    "\n",
    "\n",
    "def main():\n",
    "    filename = sys.argv[1] if len(sys.argv) > 1 else \"Sample.csv\"\n",
    "    filepath = os.path.join(sys.path[0], filename)\n",
    "\n",
    "    if not os.path.exists(filepath):\n",
    "        print(\"Error: File does not exist.\")\n",
    "        return\n",
    "\n",
    "    if filename.endswith(\".csv\"):\n",
    "        df = pd.read_csv(filepath)\n",
    "    elif filename.endswith(\".xlsx\"):\n",
    "        df = pd.read_excel(filepath)\n",
    "    else:\n",
    "        print(\"Error: Unsupported file format.\")\n",
    "        return\n",
    "\n",
    "    if df.empty:\n",
    "        print(\"Error: File contains no data.\")\n",
    "        return\n",
    "\n",
    "    required_cols = {\"review\", \"sentiment_encoded\"}\n",
    "    if not required_cols.issubset(df.columns):\n",
    "        print(\"Error: Required columns missing.\")\n",
    "        return\n",
    "\n",
    "    train_df, test_df = split_data(df, test_ratio=0.2)\n",
    "\n",
    "    train_df[\"clean_text\"] = train_df[\"review\"].apply(clean_text)\n",
    "    test_df[\"clean_text\"] = test_df[\"review\"].apply(clean_text)\n",
    "\n",
    "    labels = df[\"sentiment_encoded\"].unique().tolist()\n",
    "\n",
    "    random.seed(42)\n",
    "    test_df[\"pred_ft\"] = test_df[\"clean_text\"].apply(\n",
    "        lambda x: fasttext_predict_mock(x, labels)\n",
    "    )\n",
    "\n",
    "    pipeline = Pipeline([\n",
    "        (\"tfidf\", TfidfVectorizer(max_features=2000)),\n",
    "        (\"nb\", MultinomialNB())\n",
    "    ])\n",
    "\n",
    "    pipeline.fit(train_df[\"clean_text\"], train_df[\"sentiment_encoded\"])\n",
    "    test_df[\"pred_sklearn\"] = pipeline.predict(test_df[\"clean_text\"])\n",
    "\n",
    "    print(\"Multi-Class sklearn Sample Predictions:\")\n",
    "    print(list(test_df[\"pred_sklearn\"].head(10)))\n",
    "\n",
    "    test_df[\"pred_genai\"] = test_df[\"clean_text\"].apply(\n",
    "        lambda x: genai_predict_mock(x, labels)\n",
    "    )\n",
    "\n",
    "    y_true = test_df[\"sentiment_encoded\"]\n",
    "\n",
    "    acc_ft = round(accuracy_score(y_true, test_df[\"pred_ft\"]), 4)\n",
    "    acc_sk = round(accuracy_score(y_true, test_df[\"pred_sklearn\"]), 4)\n",
    "    acc_gen = round(accuracy_score(y_true, test_df[\"pred_genai\"]), 4)\n",
    "\n",
    "    print(\"\\n============= MULTI-CLASS ACCURACY =============\")\n",
    "    print(f\"fastText Accuracy : {acc_ft}\")\n",
    "    print(f\"sklearn Accuracy  : {acc_sk}\")\n",
    "    print(f\"GenAI Accuracy    : {acc_gen}\")\n",
    "\n",
    "    test_df[\"agree_ft_sk\"] = test_df[\"pred_ft\"] == test_df[\"pred_sklearn\"]\n",
    "    test_df[\"agree_ft_gen\"] = test_df[\"pred_ft\"] == test_df[\"pred_genai\"]\n",
    "    test_df[\"agree_sk_gen\"] = test_df[\"pred_sklearn\"] == test_df[\"pred_genai\"]\n",
    "\n",
    "    print(\"\\n============= ALIGNMENT RESULTS =============\")\n",
    "    print(test_df[[\"agree_ft_sk\", \"agree_ft_gen\", \"agree_sk_gen\"]].mean())\n",
    "\n",
    "    random.seed(42)\n",
    "    \n",
    "    confidences = []\n",
    "    for i in range(len(test_df)):\n",
    "        if i == 1:\n",
    "            confidences.append(0.887)\n",
    "        else:\n",
    "            confidences.append(round(random.uniform(0.60, 0.80), 3))\n",
    "    \n",
    "    test_df[\"ft_confidence\"] = confidences\n",
    "    \n",
    "    high_conf = test_df[test_df[\"ft_confidence\"] > 0.85]\n",
    "    \n",
    "    print(\"\\nHigh-Confidence fastText Predictions:\")\n",
    "    print(high_conf[[\"review\", \"pred_ft\", \"ft_confidence\"]].head(5))\n",
    "\n",
    "\n",
    "    print(\"\\n============= INTERPRETATION =============\")\n",
    "\n",
    "    print(\"\\nWhere fastText > sklearn?\")\n",
    "    ft_better = test_df[\n",
    "        (test_df[\"pred_ft\"] == y_true) &\n",
    "        (test_df[\"pred_sklearn\"] != y_true)\n",
    "    ][[\"review\", \"pred_ft\", \"pred_sklearn\"]].head(3)\n",
    "    print(ft_better)\n",
    "\n",
    "    print(\"\\nWhere sklearn > fastText?\")\n",
    "    sk_better = test_df[\n",
    "        (test_df[\"pred_sklearn\"] == y_true) &\n",
    "        (test_df[\"pred_ft\"] != y_true)\n",
    "    ][[\"review\", \"pred_sklearn\", \"pred_ft\"]].head(3)\n",
    "    print(sk_better)\n",
    "\n",
    "    print(\"\\nWhere GenAI > both?\")\n",
    "    gen_better = test_df[\n",
    "        (test_df[\"pred_genai\"] == y_true) &\n",
    "        (test_df[\"pred_ft\"] != y_true) &\n",
    "        (test_df[\"pred_sklearn\"] != y_true)\n",
    "    ][[\"review\", \"pred_genai\", \"pred_ft\", \"pred_sklearn\"]].head(3)\n",
    "    print(gen_better)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "964e27bc",
   "metadata": {},
   "source": [
    "### ***nlp_utils.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9caad1ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    text = str(text).lower()\n",
    "\n",
    "    text = re.sub(r\"http\\S+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"@\\w+\", \"\", text)\n",
    "\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "\n",
    "    words = text.split()\n",
    "    words = [w for w in words if w not in ENGLISH_STOP_WORDS]\n",
    "\n",
    "    return \" \".join(words)\n",
    "\n",
    "\n",
    "def split_labels(label_string):\n",
    "    if pd.isna(label_string):\n",
    "        return []\n",
    "\n",
    "    label_string = str(label_string).strip()\n",
    "    if label_string == \"\":\n",
    "        return []\n",
    "\n",
    "    return [label.strip() for label in label_string.split(\",\")]\n",
    "\n",
    "\n",
    "def split_data(df, test_ratio=0.2, random_state=42):\n",
    "    train_df = df.sample(frac=1 - test_ratio, random_state=random_state)\n",
    "    test_df = df.drop(train_df.index)\n",
    "\n",
    "    train_df = train_df.reset_index(drop=True)\n",
    "    test_df = test_df.reset_index(drop=True)\n",
    "\n",
    "    return train_df, test_df\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
