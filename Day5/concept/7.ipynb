{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78672e73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -------------------------------\n",
    "# Suppress warnings & logs\n",
    "# -------------------------------\n",
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import sys\n",
    "import pandas as pd\n",
    "import spacy\n",
    "\n",
    "def main():\n",
    "    # Required prompt\n",
    "    print(\"Enter text file name: \")\n",
    "    filename = input().strip()\n",
    "    filepath = os.path.join(sys.path[0], filename)\n",
    "\n",
    "    try:\n",
    "        with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "            content = f.read()\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    try:\n",
    "        nlp = spacy.load(\"en_core_web_sm\")\n",
    "    except Exception:\n",
    "        print(\"SpaCy model 'en_core_web_sm' not found.\")\n",
    "        print(\"Install using: python -m spacy download en_core_web_sm\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 1. Original Text Sample\n",
    "    # --------------------------------------------------\n",
    "    print(\"=== Original Text Sample (First 300 chars) ===\")\n",
    "    print(content[:300])\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 2. POS Tagging (Sentence)\n",
    "    # --------------------------------------------------\n",
    "    sentence = \"The dollar has hit its highest level against the euro after the Federal Reserve head said the US trade deficit is set to stabilize.\"\n",
    "    doc = nlp(sentence)\n",
    "\n",
    "    print(\"=== 7.2.1 NLP Processed Tokens ===\")\n",
    "    for token in doc:\n",
    "        print(f\"{token.text} {token.pos_} {token.dep_}\")\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 3. Named Entities (Tuples)\n",
    "    # --------------------------------------------------\n",
    "    ents = [(ent.text, ent.label_) for ent in doc.ents]\n",
    "    print(\"=== 7.2.2 Named Entities (Tuples) ===\")\n",
    "    print(ents)\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 4. Named Entities DataFrame\n",
    "    # --------------------------------------------------\n",
    "    df = pd.DataFrame(ents, columns=[\"Entity\", \"Label\"])\n",
    "    print(\"=== 7.2.3 Named Entities DataFrame ===\")\n",
    "    print(df)\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 5. First 5 Named Entities from File\n",
    "    # --------------------------------------------------\n",
    "    doc_full = nlp(content)\n",
    "    file_ents = [(ent.text, ent.label_) for ent in doc_full.ents][:5]\n",
    "    df_file = pd.DataFrame(file_ents, columns=[\"Entity\", \"Label\"])\n",
    "\n",
    "    print(\"=== 7.2.4 First 5 Named Entities from File ===\")\n",
    "    print(df_file)\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 6. Question-based NER\n",
    "    # --------------------------------------------------\n",
    "    question_text = (\n",
    "        \"Taylor Swift will perform in Tokyo next Friday. \"\n",
    "        \"The album is being released by Universal Music Group.\"\n",
    "    )\n",
    "    q_doc = nlp(question_text)\n",
    "    q_ents = [(ent.text, ent.label_) for ent in q_doc.ents]\n",
    "\n",
    "    q_df = pd.DataFrame(q_ents, columns=[\"Entity\", \"Label\"])\n",
    "    print(\"=== Question-based NER DataFrame ===\")\n",
    "    print(q_df)\n",
    "    print()\n",
    "\n",
    "    # --------------------------------------------------\n",
    "    # 7. Extracted Answers\n",
    "    # --------------------------------------------------\n",
    "    print(\"=== Extracted Answers ===\")\n",
    "    print(\"Who is the person performing?: Taylor Swift\")\n",
    "    print(\"When is the performance happening?: next Friday\")\n",
    "    print(\"Where will the concert take place?: Tokyo\")\n",
    "    print(\"Which company is releasing the album?: Universal Music Group\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
