{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee7f522",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "import sys\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "import spacy\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "def main():\n",
    "    filename = input(\"Enter text file name: \")\n",
    "    filepath = os.path.join(sys.path[0], filename)\n",
    "    \n",
    "    try:\n",
    "        with open(filepath, 'r', encoding='utf-8') as file:\n",
    "            content = file.read()\n",
    "    except FileNotFoundError:\n",
    "        print(\"Error: file not found\")\n",
    "        sys.exit(1)\n",
    "    \n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    doc = nlp(content)\n",
    "    \n",
    "    spacy_stopwords = STOP_WORDS\n",
    "    spacy_stopwords |= {\"officially\", \"announced\", \"present\", \"run\"}\n",
    "    spacy_stopwords -= {\"hence\", \"every\", \"he\"} \n",
    "    \n",
    "    filtered_tokens = [token.lemma_.lower()\n",
    "                        for token in doc \n",
    "                        if token.text.lower() not in spacy_stopwords \n",
    "                        and not token.is_punct\n",
    "                        and not token.is_space]\n",
    "                           \n",
    "    print(\"Filtered Tokens (First 20):\")\n",
    "    print(filtered_tokens[:20])\n",
    "    print()\n",
    "    \n",
    "    cleaned_text = \" \".join(filtered_tokens)\n",
    "    \n",
    "    print(\"Cleaned Text Sample:\")\n",
    "    print(cleaned_text[:200])\n",
    "\n",
    "main()\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
