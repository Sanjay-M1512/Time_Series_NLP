{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c7e3a8c5",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b3cbad7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"]='3'\n",
    "import spacy\n",
    "from nlp_module import *\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "\n",
    "sentence = \"LOL LOL slay slay slay queen.\"\n",
    "clean_sentence = read_from_sentence(sentence, nlp)\n",
    "\n",
    "print(\"Cleaned Sentence:\")\n",
    "print(clean_sentence)\n",
    "\n",
    "vec_s, bow_s = convert_bow_counter([clean_sentence])\n",
    "print(\"\\nBoW Word Frequencies (Sentence):\")\n",
    "\n",
    "for word, idx in vec_s.vocabulary_.items():\n",
    "    print(word, \":\", int(bow_s[0, idx]))\n",
    "    \n",
    "doc = read_from_file(\"Sample.txt\")\n",
    "clean_docs = preprocess_using_spaCy(doc, nlp)\n",
    "vec_d, bow_d = convert_bow_counter(clean_docs)\n",
    "\n",
    "print(\"BoW Word Frequencies (Business Data):\")\n",
    "prepare_output_text(vec_d, bow_d)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42e603d5",
   "metadata": {},
   "source": [
    "### ***NLP_Modules.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc231dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "def read_from_file(filename):\n",
    "    path = os.path.join(sys.path[0], filename)\n",
    "    with open(path, \"r\", encoding=\"utf-8\") as f:\n",
    "        return [line.strip() for line in f if line.strip()]\n",
    "\n",
    "def read_from_sentence(sentence, nlp):\n",
    "    doc = nlp(sentence.lower())\n",
    "    return \" \".join([t.text for t in doc if t.is_alpha and not t.is_stop])\n",
    "\n",
    "def preprocess_using_spaCy(documents, nlp):\n",
    "    clean_docs = []\n",
    "    for d in documents:\n",
    "        doc = nlp(d.lower())\n",
    "        clean_docs.append(\" \".join([t.text for t in doc if t.is_alpha and not t.is_stop]))\n",
    "    return clean_docs\n",
    "\n",
    "def convert_bow_counter(clean_docs):\n",
    "    vectorizer = CountVectorizer()\n",
    "    bow = vectorizer.fit_transform(clean_docs)\n",
    "    return vectorizer, bow\n",
    "\n",
    "def prepare_output_text(vectorizer, bow_matrix):\n",
    "    totals = bow_matrix.sum(axis=0)\n",
    "    for word, idx in vectorizer.vocabulary_.items():\n",
    "        print(word, \":\", int(totals[0, idx]))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
