{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23262368",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e5938a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "\n",
    "import numpy as np\n",
    "import spacy\n",
    "from nlp_module import *\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "VECTOR_SIZE = nlp.vocab.vectors_length or 300\n",
    "\n",
    "documents = [\n",
    "    \"news article\",\n",
    "    \"ad sales boost time warner profit\",\n",
    "    \"quarterly profits at us media giant timewarner jumped to bn m\",\n",
    "    \"time warner said on friday that it now owns of searchengine google\"\n",
    "]\n",
    "\n",
    "cleaned_docs = preprocess_docs(documents)\n",
    "\n",
    "print(\"\\nCleaned Documents:\")\n",
    "for i, doc in enumerate(cleaned_docs, start=1):\n",
    "    print(f\"{i}: {doc}\")\n",
    "\n",
    "king_vec = get_word_vector(nlp, \"king\", VECTOR_SIZE)\n",
    "print(\"\\nWord Vector for 'king' (first 10 dims):\")\n",
    "print(king_vec[:10])\n",
    "\n",
    "doc_vectors = get_document_embeddings(nlp, cleaned_docs, VECTOR_SIZE)\n",
    "print(\"\\nDocument Embedding Shape:\", doc_vectors.shape)\n",
    "\n",
    "doc_sim = cosine_sim_embeddings(doc_vectors)\n",
    "print(\"\\nCosine Similarity Between Documents:\")\n",
    "print(np.round(doc_sim, 3))\n",
    "\n",
    "sentence = \"dog cat car skym apple\"\n",
    "sim_matrix, words_used = word_similarity(nlp, sentence, VECTOR_SIZE)\n",
    "\n",
    "if sim_matrix is not None:\n",
    "    print(\"\\nWord Similarity Matrix (words with vectors):\")\n",
    "    for i, w1 in enumerate(words_used):\n",
    "        for j, w2 in enumerate(words_used):\n",
    "            if j > i:\n",
    "                print(f\"{w1} ↔ {w2} : {sim_matrix[i, j]:.3f}\")\n",
    "\n",
    "print(\"\\nObservations:\")\n",
    "print(\"• 'dog' and 'cat' have high similarity due to both being animals.\")\n",
    "print(\"• 'car' is moderately similar to 'dog' and 'cat' due to physical object context.\")\n",
    "print(\"• 'skym' may be OOV → low similarity with other words.\")\n",
    "print(\"• Embeddings capture meaning beyond frequency (unlike TF-IDF).\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec794f8a",
   "metadata": {},
   "source": [
    "### ***NLP_Modules.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d7a1274",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.lower()\n",
    "    text = re.sub(r\"[^a-z\\s]\", \"\", text)\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n",
    "\n",
    "def preprocess_docs(docs):\n",
    "    return [clean_text(d) for d in docs if d.strip()]\n",
    "\n",
    "def get_word_vector(nlp, word, vector_size):\n",
    "    doc = nlp(word)\n",
    "    if doc.has_vector:\n",
    "        return doc.vector\n",
    "    return np.zeros(vector_size)\n",
    "\n",
    "def get_document_embeddings(nlp, docs, vector_size):\n",
    "    vectors = []\n",
    "    for doc in nlp.pipe(docs):\n",
    "        if doc.has_vector:\n",
    "            vectors.append(doc.vector)\n",
    "        else:\n",
    "            vectors.append(np.zeros(vector_size))\n",
    "    return np.vstack(vectors)\n",
    "\n",
    "def cosine_sim_embeddings(vectors):\n",
    "    return cosine_similarity(vectors)\n",
    "\n",
    "def word_similarity(nlp, sentence, vector_size):\n",
    "    words = sentence.split()\n",
    "    valid_words = []\n",
    "    vectors = []\n",
    "\n",
    "    for w in words:\n",
    "        vec = get_word_vector(nlp, w, vector_size)\n",
    "        if np.any(vec):\n",
    "            valid_words.append(w)\n",
    "            vectors.append(vec)\n",
    "\n",
    "    if len(vectors) < 2:\n",
    "        return None, valid_words\n",
    "\n",
    "    vectors = np.vstack(vectors)\n",
    "    sim_matrix = cosine_similarity(vectors)\n",
    "    return sim_matrix, valid_words"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
