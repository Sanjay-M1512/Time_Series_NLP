{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbcff618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\"\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "try:\n",
    "    import spacy\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "except OSError:\n",
    "    print(\"spaCy model 'en_core_web_sm' not found.\")\n",
    "    print(\"Install it using: python -m spacy download en_core_web_sm\")\n",
    "    sys.exit(1)\n",
    "\n",
    "\n",
    "def main():\n",
    "    filename = input(\"Enter sports news text file name: \")\n",
    "\n",
    "    filepath = os.path.join(sys.path[0], filename)\n",
    "\n",
    "    if not os.path.isfile(filepath):\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    with open(filepath, \"r\", encoding=\"utf-8\") as f:\n",
    "        content = f.read()\n",
    "\n",
    "    print(\"=== Original Text Sample (First 300 chars) ===\")\n",
    "    print(content[:300])\n",
    "    print()\n",
    "\n",
    "    documents = [doc.strip() for doc in content.split('---') if doc.strip()]\n",
    "\n",
    "    cleaned_docs = []\n",
    "    all_tokens = []\n",
    "\n",
    "    for doc in documents:\n",
    "        spacy_doc = nlp(doc.lower())\n",
    "        tokens = [\n",
    "            token.text\n",
    "            for token in spacy_doc\n",
    "            if not token.is_stop and not token.is_punct and not token.is_space\n",
    "        ]\n",
    "        all_tokens.extend(tokens)\n",
    "        cleaned_docs.append(\" \".join(tokens))\n",
    "\n",
    "    print(\"=== Cleaned Text Sample ===\")\n",
    "    print(all_tokens[:50])\n",
    "    print()\n",
    "\n",
    "    bow_vectorizer = CountVectorizer()\n",
    "    bow_matrix = bow_vectorizer.fit_transform(cleaned_docs)\n",
    "\n",
    "    tfidf_vectorizer = TfidfVectorizer()\n",
    "    tfidf_matrix = tfidf_vectorizer.fit_transform(cleaned_docs)\n",
    "\n",
    "    feature_names = tfidf_vectorizer.get_feature_names()\n",
    "    idf_values = tfidf_vectorizer.idf_\n",
    "\n",
    "    print(\"=== TF-IDF Features ===\")\n",
    "    print(list(feature_names))\n",
    "    print()\n",
    "\n",
    "    print(\"=== IDF Values ===\")\n",
    "    for word, idf in zip(feature_names, idf_values):\n",
    "        print(f\"{word} : {idf:.4f}\")\n",
    "    print()\n",
    "\n",
    "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=feature_names)\n",
    "    print(\"=== TF-IDF Matrix ===\")\n",
    "    print(tfidf_df.round(4))\n",
    "    print()\n",
    "\n",
    "    embeddings = np.array([nlp(doc).vector for doc in cleaned_docs])\n",
    "    print(\"=== Word Embedding Vectors ===\")\n",
    "    print(embeddings)\n",
    "    print()\n",
    "\n",
    "    print(\"=== Vector Shapes ===\")\n",
    "    print(f\"BoW shape: {bow_matrix.shape}\")\n",
    "    print(f\"TF-IDF shape: {tfidf_matrix.shape}\")\n",
    "    print(f\"Embedding shape: {embeddings.shape}\")\n",
    "    print()\n",
    "\n",
    "    print(\"=== Cosine Similarity (BoW) ===\")\n",
    "    print(cosine_similarity(bow_matrix))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Cosine Similarity (TF-IDF) ===\")\n",
    "    print(cosine_similarity(tfidf_matrix))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Cosine Similarity (Embeddings) ===\")\n",
    "    print(cosine_similarity(embeddings))\n",
    "    print()\n",
    "\n",
    "    print(\"=== Observations ===\")\n",
    "    print(\"1. Bag-of-Words considers only word frequency.\")\n",
    "    print(\"2. TF-IDF highlights important words across documents.\")\n",
    "    print(\"3. Word embeddings capture semantic meaning and context.\")\n",
    "    print(\"4. Embedding similarity reflects deeper relationships between sports news articles.\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
