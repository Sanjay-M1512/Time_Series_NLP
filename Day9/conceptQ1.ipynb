{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d2cc538",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6dc5dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "\n",
    "from nlp_utils import clean_text, split_labels\n",
    "\n",
    "warnings.simplefilter(action='ignore')\n",
    "\n",
    "\n",
    "def main():\n",
    "    filename = input().strip()\n",
    "\n",
    "    try:\n",
    "        if filename.endswith(\".csv\"):\n",
    "            fp143=os.path.join(sys.path[0],filename)\n",
    "            df = pd.read_csv(fp143)\n",
    "        elif filename.endswith(\".xlsx\") or filename.endswith(\".xls\"):\n",
    "            df = pd.read_excel(filename)\n",
    "        else:\n",
    "            print(\"Unsupported file format\")\n",
    "            return\n",
    "    except Exception:\n",
    "        return\n",
    "\n",
    "    if 'text' not in df.columns:\n",
    "        print(\"Column 'text' not found\")\n",
    "        return\n",
    "\n",
    "    print(\"=== First 5 Rows ===\")\n",
    "    print(df.head())\n",
    "\n",
    "    print()\n",
    "    print(f\"Number of samples: {len(df)}\")\n",
    "\n",
    "    print()\n",
    "    print(\"=== Data Types ===\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print()\n",
    "    print(\"=== Missing Values ===\")\n",
    "    print(df.isnull().sum())\n",
    "\n",
    "    df['clean_text'] = df['text'].apply(clean_text)\n",
    "\n",
    "    print()\n",
    "    print(\"=== Sample Cleaned Text ===\")\n",
    "    print(df[['text', 'clean_text']].head())\n",
    "\n",
    "    vectorizer = TfidfVectorizer(max_features=2000)\n",
    "    tfidf_matrix = vectorizer.fit_transform(df['clean_text'])\n",
    "\n",
    "    print()\n",
    "    print(f\"TF-IDF Shape: {tfidf_matrix.shape}\")\n",
    "\n",
    "    if 'sentiment' in df.columns:\n",
    "        le = LabelEncoder()\n",
    "        df['sentiment_encoded'] = le.fit_transform(df['sentiment'])\n",
    "\n",
    "        mapping = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "        print()\n",
    "        print(\"Sentiment Classes:\", mapping)\n",
    "\n",
    "    if 'emotion_labels' in df.columns:\n",
    "        df['emotion_list'] = df['emotion_labels'].apply(split_labels)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        emotion_matrix = mlb.fit_transform(df['emotion_list'])\n",
    "\n",
    "        print()\n",
    "        print(\"Emotion Classes:\", mlb.classes_)\n",
    "        print(f\"Emotion Encoding Shape: {emotion_matrix.shape}\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93f8b13",
   "metadata": {},
   "source": [
    "### ***nlp_utils***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb75617",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Cleans and normalizes input text for NLP processing\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        return \"\"\n",
    "\n",
    "    text = text.lower()\n",
    "    text = re.sub(r'http\\S+|www\\S+', '', text)\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text\n",
    "\n",
    "\n",
    "def split_labels(label_text):\n",
    "    \"\"\"\n",
    "    Converts comma-separated emotion labels into a list\n",
    "    \"\"\"\n",
    "    if not isinstance(label_text, str):\n",
    "        return []\n",
    "\n",
    "    labels = [l.strip() for l in label_text.split(',') if l.strip()]\n",
    "    return labels"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
