{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b11196f2",
   "metadata": {},
   "source": [
    "### ***Main.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc32992b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import warnings\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "from nlp_utils import clean_text, split_labels, split_data\n",
    "\n",
    "def main():\n",
    "    f143 = input(\"Enter dataset filename (CSV or Excel): \").strip()\n",
    "    file_path = os.path.join(sys.path[0], f143)\n",
    "\n",
    "    try:\n",
    "        if f143.endswith(\".csv\"):\n",
    "            df = pd.read_csv(file_path)\n",
    "        elif filename.endswith((\".xls\", \".xlsx\")):\n",
    "            df = pd.read_excel(file_path, engine=\"openpyxl\")\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported file type. Use CSV or Excel.\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading file: {e}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    print(\"\\n=== First 5 Rows ===\")\n",
    "    print(df.head())\n",
    "    print(f\"\\nNumber of samples: {df.shape[0]}\")\n",
    "    print(\"\\n=== Data Types ===\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    train, test = split_data(df)\n",
    "    print(f\"\\nTrain: {train.shape[0]}, Test: {test.shape[0]}\")\n",
    "\n",
    "    if \"review\" not in train.columns:\n",
    "        print(\"Column 'review' not found â€” cannot clean text.\")\n",
    "        sys.exit(1)\n",
    "\n",
    "    train[\"cleaned_text\"] = train[\"review\"].apply(clean_text)\n",
    "    test[\"cleaned_text\"] = test[\"review\"].apply(clean_text)\n",
    "\n",
    "    print(\"\\n=== Sample Cleaned Text ===\")\n",
    "    print(train[[\"review\", \"cleaned_text\"]].head())\n",
    "\n",
    "    tfidf = TfidfVectorizer(max_features=3000)\n",
    "    X_train_tfidf = tfidf.fit_transform(train[\"cleaned_text\"])\n",
    "    X_test_tfidf = tfidf.transform(test[\"cleaned_text\"])\n",
    "    print(\"\\n=== TF-IDF Shapes ===\")\n",
    "    print(\"Train:\", X_train_tfidf.shape, \"Test:\", X_test_tfidf.shape)\n",
    "\n",
    "    tfidf_file = os.path.join(sys.path[0], \"tfidf.pkl\")\n",
    "    with open(tfidf_file, \"wb\") as f:\n",
    "        pickle.dump(tfidf, f)\n",
    "\n",
    "    if \"binary_sentiment\" in train.columns:\n",
    "        binary_model = LogisticRegression(max_iter=1000)\n",
    "        binary_model.fit(X_train_tfidf, train[\"binary_sentiment\"])\n",
    "        binary_preds = binary_model.predict(X_test_tfidf)\n",
    "\n",
    "        print(\"\\n=== Binary Classification Predictions ===\")\n",
    "        print(binary_preds[:10])\n",
    "\n",
    "    if \"sentiment_encoded\" in train.columns:\n",
    "        multi_model = MultinomialNB()\n",
    "        multi_model.fit(X_train_tfidf, train[\"sentiment_encoded\"])\n",
    "        multi_preds = multi_model.predict(X_test_tfidf)\n",
    "\n",
    "        print(\"\\n=== Multi-Class Classification Predictions ===\")\n",
    "        print(multi_preds[:10])\n",
    "\n",
    "    if \"emotion_labels\" in train.columns:\n",
    "        train[\"emotion_list\"] = train[\"emotion_labels\"].apply(split_labels)\n",
    "        test[\"emotion_list\"] = test[\"emotion_labels\"].apply(split_labels)\n",
    "\n",
    "        mlb = MultiLabelBinarizer()\n",
    "        Y_train_mlabel = mlb.fit_transform(train[\"emotion_list\"])\n",
    "        Y_test_mlabel = mlb.transform(test[\"emotion_list\"])\n",
    "\n",
    "        multilabel_model = OneVsRestClassifier(\n",
    "            LogisticRegression(max_iter=1000)\n",
    "        )\n",
    "        multilabel_model.fit(X_train_tfidf, Y_train_mlabel)\n",
    "        multilabel_preds = multilabel_model.predict(X_test_tfidf)\n",
    "\n",
    "        print(\"\\n=== Multi-Label Classification Predictions ===\")\n",
    "        print(multilabel_preds[:5])\n",
    "        print(\"Associated classes:\", mlb.classes_)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "494957bb",
   "metadata": {},
   "source": [
    "### ***nlp_utils.py***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a78b5ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "ENGLISH_STOPWORDS = set(\"\"\"\n",
    "a about above after again against all am an and any are as at be because been before\n",
    "being below between both but by do does doing down during each few for from further had\n",
    "has have having he her here hers him himself his how i if in into is it its itself me\n",
    "more most my myself no nor not of off on once only or other our ours ourselves out over\n",
    "own same she should so some such than that the their theirs them themselves then there\n",
    "these they this those through to too under until up very was we were what when where which\n",
    "while who whom why with you your yours yourself yourselves\n",
    "\"\"\".split())\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Lowercase, remove URLs, mentions, punctuation, numbers, stopwords\n",
    "    \"\"\"\n",
    "    text = str(text).lower()\n",
    "    text = re.sub(r\"http\\S+|@\\w+|[^a-z\\s]\", \"\", text)\n",
    "    words = [w for w in text.split() if w not in ENGLISH_STOPWORDS]\n",
    "    return \" \".join(words)\n",
    "\n",
    "def split_labels(label_string):\n",
    "    \"\"\"\n",
    "    Converts a comma-separated string into a list of labels.\n",
    "    Returns empty list if input is NaN or empty.\n",
    "    \"\"\"\n",
    "    if pd.isna(label_string) or label_string == \"\":\n",
    "        return []\n",
    "    return [l.strip() for l in label_string.split(\",\")]\n",
    "\n",
    "def split_data(df, test_ratio=0.2, random_state=42):\n",
    "    \"\"\"\n",
    "    Randomly splits DataFrame into train and test sets\n",
    "    \"\"\"\n",
    "    train = df.sample(frac=1 - test_ratio, random_state=random_state)\n",
    "    test = df.drop(train.index)\n",
    "    return train.reset_index(drop=True), test.reset_index(drop=True)\n",
    "\n",
    "def create_binary_label(df, column, positive_value):\n",
    "    \"\"\"\n",
    "    Converts a column into binary 0/1 labels.\n",
    "    positive_value -> 1, all others -> 0\n",
    "    \"\"\"\n",
    "    return df[column].apply(lambda x: 1 if x == positive_value else 0)\n",
    "\n",
    "def encode_labels(df, column):\n",
    "    \"\"\"\n",
    "    Label encodes a categorical column\n",
    "    Returns: encoded_series, label_encoder\n",
    "    \"\"\"\n",
    "    from sklearn.preprocessing import LabelEncoder\n",
    "    le = LabelEncoder()\n",
    "    encoded = le.fit_transform(df[column])\n",
    "    return encoded, le"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
